这篇文章主要总结了几种流行的强化学习算法。作为一篇介绍性的文章，它不预设你有强化学习相关的任何知识，但是由于一些我们不准备在本文中探讨的方法论的问题，你最好应该明白基本的机器学习知识，以及神经网络的原理，包括结构、反向传播的训练方式等。（简单来说，只要你看完了吴恩达在courera上的那个著名的课程就合格了）
同时，本文会引述原始论文中的一些数学推导，所以相关的概率论知识会对理解这些公式有帮助。如果你不准备纠结数学形式而想看算法原理，这些章节可以跳过。

# 强化学习是什么
# 引入
我们会通过学自行车这个日常的行为活动来引入强化学习（Reinforce Learning，RL）的一些关键概念。
笔者直到大学本科才学会骑自行车，这段经历给我最大的感受就是，学骑这个东西真的是一个肌肉记忆的过程。不管叫笔者骑车的人如何给出一些抽象的规则，还是无法保持平衡，最后还就是通过不断的尝试才能骑起来。
这里，我们有了一个典型的强化学习的场景。笔者，一个个体，我们称为agent，通过与某种系统（自行车），我们称为环境，进行许多次的交互，来学会某种能力。这个能力就是，在某种情况（称为state）下，做出相应的操作（称为action），从而能得到某种好的结果（reward），比方说，骑得很远。


强化学习是一类这样的学习：agent通过和**环境的交互**来学习。
从方法上来说，一般RL是一种监督学习，你需要预先知道“正确”的输入和输出。
从过程上来说，RL和监督学习的不同就在于它有一个环境，我们的模型可以和环境交互，去获得一些尝试的结果，从而制造出新的训练数据。RL的训练过程是一个**试错过程**。
# 